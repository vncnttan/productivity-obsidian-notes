Vision Language Model: Learn simultantenously from images and texts to tackle many tasks.

Leaderboards:
[Vision Arena (Testing VLMs side-by-side) - a Hugging Face Space by WildVision](https://huggingface.co/spaces/WildVision/vision-arena)
![[Pasted image 20250102123328.png]]

[Open VLM Leaderboard - a Hugging Face Space by opencompass](https://huggingface.co/spaces/opencompass/open_vlm_leaderboard)
![[Pasted image 20250102123236.png]]

Benchmark Evaluation: [open-compass/VLMEvalKit: Open-source evaluation toolkit of large vision-language models (LVLMs), support 160+ VLMs, 50+ benchmarks](https://github.com/open-compass/VLMEvalKit)



- MMMU
	- The most comprehensive
	- Require college-level subject knowledge and reasoning (accorss different disciplines such as arts and engineering)
- MMBench
	- 3000 single-choice questions over 20 different skills (inc. OCR, Object Localization, and more~)
- Technical Details


Paper Links:
 - GPT - 4V(ision) system card: [GPT-4V(ision) system card | OpenAI](https://openai.com/index/gpt-4v-system-card/)
 - GPT - 4o [Hello GPT-4o | OpenAI](https://openai.com/index/hello-gpt-4o/)
 - Gemini [[2312.11805] Gemini: A Family of Highly Capable Multimodal Models](https://arxiv.org/abs/2312.11805)
 - Claude 3.5 [Introducing Claude 3.5 Sonnet \ Anthropic](https://www.anthropic.com/news/claude-3-5-sonnet)

   