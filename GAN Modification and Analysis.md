#### Before Modification
![[Pasted image 20241127085004.png]]
![[Pasted image 20241127084942.png]]

#### Analysis

###### Activation Function ReLU
Model GAN dari code awalnya menggunakan ReLU sebagai activation function di layer Generator dan Discriminatornya. ReLU kurang efektif digunakan karena ada beberapa value yang negative bisa dijadikan sebagai pembelajaran di neuron. 

###### Learning Rate
#### After Modification



